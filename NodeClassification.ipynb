{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPgbDTkgnRJpn578vrfhmjK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Subhashree1202/GCNN_NodeClassification/blob/main/NodeClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZ0DFeafytXN"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os.path as osp\n",
        "from PIL import Image as im\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import Planetoid,Amazon\n",
        "from torch_geometric.logging import init_wandb, log\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.layers import SimpleRNN, LSTM, GRU\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "from distutils.version import LooseVersion as LV\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import np_utils\n",
        "from collections import defaultdict\n",
        "import random\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "datasets= ['Cora','Citeseer','Pubmed','Computers','Photo']\n",
        "args_dataset = datasets[0]\n",
        "args_lr = 0.01\n",
        "args_epochs = 200\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "path = osp.join('data', 'Planetoid')\n",
        "#dataset = Amazon(path, args_dataset, transform=T.NormalizeFeatures())\n",
        "dataset = Planetoid(path, args_dataset, transform=T.NormalizeFeatures())\n",
        "data = dataset[0]\n",
        "data1 = data.to(device)\n",
        "features = data.x.numpy()\n",
        "features.reshape((features.shape[0], features.shape[1], 1))\n",
        "\n",
        "y = data.y.numpy()\n",
        "y = np_utils.to_categorical(y, dataset.num_classes)\n",
        "\n",
        "def rnn_model(rows, cols, nb_classes, hidden1, hidden2):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Recurrent layers supported: SimpleRNN, LSTM, GRU:\n",
        "    model.add(SimpleRNN(hidden1,\n",
        "                        input_shape=(rows, cols),\n",
        "                        return_sequences=True))\n",
        "    model.add(SimpleRNN(hidden2))\n",
        "\n",
        "    model.add(Dense(units=nb_classes))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "def rnn_feature_model(rows, cols , hidden1, hidden2):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Recurrent layers supported: SimpleRNN, LSTM, GRU:\n",
        "    model.add(SimpleRNN(hidden1,\n",
        "                        input_shape=(rows, cols),\n",
        "                        return_sequences=True))\n",
        "    model.add(SimpleRNN(hidden2))\n",
        "    return model\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, drops, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, int(hidden_channels), cached=True,\n",
        "                             normalize=True)\n",
        "        self.conv2 = GCNConv(int(hidden_channels), out_channels, cached=True,\n",
        "                             normalize=True)\n",
        "        self.drops = drops\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight=None):\n",
        "        x = F.dropout(x, p=self.drops, training=self.training)\n",
        "        x = self.conv1(x, edge_index, edge_weight).relu()\n",
        "        x = F.dropout(x, p=self.drops, training=self.training)\n",
        "        x = self.conv2(x, edge_index, edge_weight)\n",
        "        return x\n",
        "\n",
        "def epsilonGreedy(epsilon, Q, state):\n",
        "        if np.random.uniform() < epsilon:\n",
        "            return random.randint(0, 2)\n",
        "        else:\n",
        "            best_next_action = np.argmax(Q[state,:])\n",
        "\n",
        "        return best_next_action\n",
        "\n",
        "def get_reward_RL_RNN(action, state):\n",
        "    modelRNN = rnn_model(features.shape[1],1, dataset.num_classes, action, state)\n",
        "    epochs = 3\n",
        "    history = modelRNN.fit(features,\n",
        "                        y,\n",
        "                        epochs=epochs,\n",
        "                        batch_size=128,\n",
        "                        verbose=2)\n",
        "    return history.history['accuracy'][-1]\n",
        "\n",
        "def get_reward_RL_GNN(shape1, action, state, ss = False):\n",
        "    model = GCN(shape1, action, state, dataset.num_classes)\n",
        "    model = model.to(device)\n",
        "    optimizer2 = torch.optim.Adam([\n",
        "        dict(params=model.conv1.parameters(), weight_decay=5e-4),\n",
        "        dict(params=model.conv2.parameters(), weight_decay=0)\n",
        "    ], lr=args_lr)\n",
        "\n",
        "    def train():\n",
        "        model.train()\n",
        "        optimizer2.zero_grad()\n",
        "        out = model(rnn_feature, data1.edge_index, data1.edge_weight)\n",
        "        loss = F.cross_entropy(out[data1.train_mask], data1.y[data.train_mask])\n",
        "        loss.backward()\n",
        "        optimizer2.step()\n",
        "        return float(loss)\n",
        "\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def test():\n",
        "        model.eval()\n",
        "        pred = model(rnn_feature, data1.edge_index, data1.edge_weight).argmax(dim=-1)\n",
        "\n",
        "        actual2 = data1.y[data1.test_mask]\n",
        "        pred2 = pred[data1.test_mask]\n",
        "\n",
        "        accs = []\n",
        "        for mask in [data1.train_mask, data1.val_mask, data1.test_mask]:\n",
        "            accs.append(int((pred[mask] == data1.y[mask]).sum()) / int(mask.sum()))\n",
        "        return accs, actual2, pred2\n",
        "\n",
        "\n",
        "    best_val_acc = final_test_acc = 0\n",
        "    train_loss = []\n",
        "    train_acc_list = []\n",
        "    val_acc_list = []\n",
        "    test_acc_list = []\n",
        "\n",
        "    for epoch in range(1, args_epochs + 1):\n",
        "        loss = train()\n",
        "        [train_acc, val_acc, tmp_test_acc], actual2, pred2 = test()\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            test_acc = tmp_test_acc\n",
        "            actual2_ = actual2\n",
        "            pred2_ = pred2\n",
        "        log(Epoch=epoch, Loss=loss, Train=train_acc, Val=val_acc, Test=test_acc)\n",
        "        train_loss.append(loss)\n",
        "        train_acc_list.append(train_acc)\n",
        "        val_acc_list.append(val_acc)\n",
        "        test_acc_list.append(test_acc)\n",
        "\n",
        "    if ss ==True:\n",
        "        plt.figure()\n",
        "        plt.plot(train_loss)\n",
        "        plt.xlabel('epoch')\n",
        "        plt.ylabel('train loss')\n",
        "\n",
        "        plt.figure()\n",
        "        plt.plot(train_acc_list)\n",
        "        plt.xlabel('epoch')\n",
        "        plt.ylabel('train accuracy')\n",
        "\n",
        "        plt.figure()\n",
        "        plt.plot(val_acc_list)\n",
        "        plt.xlabel('epoch')\n",
        "        plt.ylabel('valid accuracy')\n",
        "\n",
        "        plt.figure()\n",
        "        plt.plot(test_acc_list)\n",
        "        plt.xlabel('epoch')\n",
        "        plt.ylabel('test accuracy')\n",
        "\n",
        "    return test_acc, actual2_, pred2_\n",
        "\n",
        "n_episodes=1\n",
        "##// hidden_numbers = np.array([[800,1000,1200],[1224, 1512, 1624]])\n",
        "hidden_numbers = np.array([[200,300,400],[250, 350, 450]])\n",
        "parameters = np.array([[8,16,32],[0.4,0.5,0.6]])\n",
        "Q_table = np.zeros((3, 3))\n",
        "\n",
        "def hiddenLayer_opt(nntype):\n",
        "  lr = 0.1\n",
        "  gamma = 0.99\n",
        "  epsilonDecayFactor = 0.99\n",
        "  epsilon = 1.0\n",
        "  min_epsilon = 0.1\n",
        "\n",
        "  for e1 in range(n_episodes):\n",
        "        print(\"episode for RL_RNN: \", e1)\n",
        "        epsilon *= epsilonDecayFactor\n",
        "        epsilon = max(min_epsilon, epsilon)\n",
        "        current_state = 0\n",
        "        step = 0\n",
        "        for k in range(1):\n",
        "            step += 1\n",
        "            action =epsilonGreedy(epsilon, Q_table, current_state)\n",
        "            if nntype == 'RNN':\n",
        "              reward = get_reward_RL_RNN(hidden_numbers[0, action],hidden_numbers[1,current_state])\n",
        "            elif nntype == 'RL':\n",
        "              reward ,_ ,_= get_reward_RL_GNN(hidden2, parameters[0,action], parameters[1,current_state], False)\n",
        "            next_state = (action + random.randint(0, 2)) % 3\n",
        "\n",
        "            best_next_action = np.argmax(Q_table[next_state,:])\n",
        "            Q_table[current_state][action] = (1-lr) * Q_table[current_state][action] \\\n",
        "                                              + lr*(reward + gamma* Q_table[next_state][best_next_action])\n",
        "\n",
        "            current_state = next_state\n",
        "\n",
        "hiddenLayer_opt('RNN')\n",
        "\n",
        "hidden1 = np.argmax(Q_table, axis=0)[0]\n",
        "hidden1 = hidden_numbers[0, hidden1]\n",
        "hidden2 = np.argmax(Q_table, axis=1)[0]\n",
        "hidden2 = hidden_numbers[1,hidden2]\n",
        "\n",
        "rnn_feature_m = rnn_feature_model(features.shape[1],1,hidden1, hidden2)\n",
        "rnn_feature = rnn_feature_m.predict(features)\n",
        "print('rnn feature shape: ', rnn_feature.shape)\n",
        "rnn_feature = torch.tensor(rnn_feature)\n",
        "\n",
        "hiddenLayer_opt('RL')\n",
        "\n",
        "hidden = np.argmax(Q_table, axis=0)[0]\n",
        "drop = np.argmax(Q_table, axis=1)[0]\n",
        "\n",
        "accuracy, actual, pred = get_reward_RL_GNN(hidden2, parameters[0,hidden], parameters[1,drop],True)\n",
        "\n",
        "confusion_matrix = metrics.confusion_matrix(actual, pred)\n",
        "print(confusion_matrix)\n",
        "\n",
        "fig, ax = plot_confusion_matrix(conf_mat=confusion_matrix)\n",
        "plt.show()"
      ]
    }
  ]
}